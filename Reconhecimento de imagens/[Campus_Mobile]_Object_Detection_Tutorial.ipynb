{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Campus_Mobile]_Object_Detection_Tutorial.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8-yl-s-WKMG"
      },
      "source": [
        "# Detecção de Objetos e Segmentação de Instâncias utilizando o TensorFlow\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/beonclaro/Campus-Mobile/blob/master/Reconhecimento%20de%20imagens/%5BCampus_Mobile%5D_Object_Detection_Tutorial.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Acessar no Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/beonclaro/Campus-Mobile/blob/master/Reconhecimento%20de%20imagens/%5BCampus_Mobile%5D_Object_Detection_Tutorial.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver código fonte no GitHub</a>\n",
        "</td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpRyXh-bdrQe",
        "colab_type": "text"
      },
      "source": [
        "Esse notebook foi construído como material de suporte para o [webinar sobre práticas de Inteligência Artificial no reconhecimento de imagens](https://www.youtube.com/watch?v=NUfQxBqnnp4), transmitido através do canal do [Programa Campus Mobile no Youtube](https://www.youtube.com/channel/UCnyoGz2f3gcta37wOKkiEKw)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnr6gpabjKM-",
        "colab_type": "text"
      },
      "source": [
        "> **Referências**:\n",
        "\n",
        "[Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)\n",
        "\n",
        "[Object Detection API Demo](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)\n",
        "\n",
        "[Detecção de objetos utilizando o TFHub](https://colab.sandbox.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFSqkTCdWKMI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "awjrpqy-6MaQ"
      },
      "source": [
        "**Importante**: Se você esta rodando este notebook na sua máquina local, por favor siga as [instruções de instalação](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md). Esse notebook inclui apenas o necessário para rodar a demo no Google Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3UGXxUii5Ym"
      },
      "source": [
        "### Instalação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGL97-GXjSUw",
        "colab": {}
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.*\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_ap_s9ajTHH"
      },
      "source": [
        "Certifique-se de que a biblioteca `pycocotools` esta instalada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bg8ZyA47i3pY",
        "colab": {}
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-vsOL3QR6kqs"
      },
      "source": [
        "Clonando o diretório `https://github.com/tensorflow/models`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ykA0c-om51s1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O219m6yWAj9l"
      },
      "source": [
        "Compilando dependências como o protobufs e instalando o pacote object_detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PY41vdYYNlXc",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s62yJyQUcYbp",
        "colab": {}
      },
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "### Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "import time\n",
        "\n",
        "from IPython.display import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "Importando o módulo object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-IMl4b6BdGO",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RYPCiag2iz_q"
      },
      "source": [
        "Patches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mF-YlMl8c_bM",
        "colab": {}
      },
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cfn_tRFOWKMO"
      },
      "source": [
        "# Preparação do modelo "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X_sEBLpVWKMQ"
      },
      "source": [
        "Neste tutorial abordaremos o processo de inferência utilizando um dos modelos disponíveis no [detection model zoo do Tensorflow](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
        "\n",
        "O processo de treinamento não será abordado em detalhe neste tutorial. Caso tenha interesse em entender mais sobre como treinar um modelo de detecção de objetos, verifique as referências abaixo:\n",
        "\n",
        "[Transferência de Aprendizado utilizando o Tensorflow](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
        "\n",
        "[Detecção de Objetos utilizando o seu próprio dataset](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ai8pLZZWKMS"
      },
      "source": [
        "## Carregando um modelo treinado previamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zm8xp-0eoItE",
        "colab": {}
      },
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "  model = model.signatures['serving_default']\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "## Carregando o mapeamento para o nome das classes\n",
        "A saída da rede neural convolucional é um número, sendo assim precisamos saber o mapeamento do número para a classe. Por exemplo, se a saída da rede for `5`, precisamos saber que isso corresponde à classe `avião`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDbpHkiWWKMX",
        "colab": {}
      },
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQShD_YEuM3N",
        "colab_type": "text"
      },
      "source": [
        "# Imagens de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFMbjZcvuMf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        " \n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irLiGyI4uS-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://www.institutonetclaroembratel.org.br/wp-content/uploads/2019/09/9_1.jpg\",\n",
        "              \"https://www.institutonetclaroembratel.org.br/wp-content/uploads/2019/09/5.jpg\",\n",
        "             \"https://www.institutonetclaroembratel.org.br/wp-content/uploads/2019/09/7.jpg\",\n",
        "             \"https://www.institutonetclaroembratel.org.br/wp-content/uploads/2019/09/6.jpg\",\n",
        "              \"https://www.institutonetclaroembratel.org.br/wp-content/uploads/2019/09/10.jpg\"]\n",
        "\n",
        "for image_url in image_urls:\n",
        "  image_path = download_and_resize_image(image_url, 800, 800)\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0_1AGhrWKMc"
      },
      "source": [
        "# Detecção de objetos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7aOtOlebK7h"
      },
      "source": [
        "Carregando um modelo de detecção de objetos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1XNT0wxybKR6",
        "colab": {}
      },
      "source": [
        "#model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "model_name = 'ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "detection_model = load_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yN1AYfAEJIGp"
      },
      "source": [
        "Verifique as dimensões de entrada do modelo, ele espera um conjunto de imagens com três canais de cores do tipo uint8:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CK4cnry6wsHY",
        "colab": {}
      },
      "source": [
        "print(detection_model.inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q8u3BjpMJXZF"
      },
      "source": [
        "O modelo retorna muitas informações na saída:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLSZpfaYwuSk",
        "colab": {}
      },
      "source": [
        "detection_model.output_dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZyKUJeuxvpT",
        "colab": {}
      },
      "source": [
        "detection_model.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JP5qZ7sXJpwG"
      },
      "source": [
        "Abaixo temos uma função que realiza a inferência em uma imagem utilizando o modelo que foi previamente carregado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ajmR_exWyN76",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  output_dict = model(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1wq0LVyMRR_"
      },
      "source": [
        "Abaixo temos uma função que chama a função que realiza a inferência e desenha os \"boxes\" na localização e com as classes que foram inferidas na imagem de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWh_1zz6aqxs",
        "colab": {}
      },
      "source": [
        "def show_inference(model, image_path):\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSeJQmHatBvv",
        "colab_type": "text"
      },
      "source": [
        "Rodando a inferência para um conjunto de imagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3a5wMHN8WKMh",
        "colab": {}
      },
      "source": [
        "#for image_path in TEST_IMAGE_PATHS:\n",
        "#  show_inference(detection_model, image_path)\n",
        "for image_url in image_urls:\n",
        "  start_time = time.time()\n",
        "  image_path = download_and_resize_image(image_url, 640, 640)\n",
        "  show_inference(detection_model, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time: {} sec\".format(end_time-start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DsspMPX3Cssg"
      },
      "source": [
        "## Segmentação de instâncias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXEZMSvgtIiC",
        "colab_type": "text"
      },
      "source": [
        "Nesta etapa vamos substituir o modelo de detecção de objetos por um modelo que realiza a segmentação de instâncias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CzkVv_n2MxKC",
        "colab": {}
      },
      "source": [
        "model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\n",
        "masking_model = load_model(\"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0S7aZi8ZOhVV"
      },
      "source": [
        "O modelo de segmentação de instâncias inclui uma saída com as as máscaras detectadas, já que a classificação neste caso é pixel à pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQ2Sj2VIOZLA",
        "colab": {}
      },
      "source": [
        "masking_model.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AS57rZlnNL7W",
        "colab": {}
      },
      "source": [
        "for image_url in image_urls:\n",
        "  start_time = time.time()\n",
        "  image_path = download_and_resize_image(image_url, 640, 640)\n",
        "  show_inference(masking_model, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time: {} sec\".format(end_time-start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLlmm9JojEKm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}